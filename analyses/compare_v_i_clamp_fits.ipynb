{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the variable relationships between voltage clamp and current clamp differ for different cre lines or layers?\n",
    "\n",
    "Question: Can we predict the parameters found by fitting current clamp data from voltage clamp data (using fits to the average first pulse trace).  If so, do these relationships differ between different cre lines or layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare voltage clamp and current clamp fits.\n",
    "# Note that these .csv files loaded here have been process though \"extract_first_pulse_fit_data_from_DB.py\"\n",
    "# \"and catagorize_goodness_of_fit_by_eye.py\"\n",
    "# A fantastic explanation of how to interpret the output and input of linear regression\n",
    "# of different catagories in statsmodels (or R) is at: \n",
    "# https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csv files.\n",
    "i_df=pd.read_csv('ML_connected_iclamp_2018_12_18.csv')\n",
    "v_df=pd.read_csv('ML_connected_vclamp_2018_12_12.csv')\n",
    "i_df['uid']=i_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)\n",
    "v_df['uid']=v_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of wacky Unnamed columns if they exist\n",
    "v_df=v_df[v_df.columns.drop(list(v_df.filter(regex='Unnamed')))]\n",
    "i_df=i_df[i_df.columns.drop(list(i_df.filter(regex='Unnamed')))]\n",
    "i_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge the any sign versus forced sign data frames\n",
    "merged_df = pd.merge(i_df, v_df, on=['uid', 'pre_cell_id', 'post_cell_id', \n",
    "                                     'distance', 'acsf','post_cre', 'pre_cre',\n",
    "                                    'boolean_connection', 'pre_layer', 'post_layer'], how='inner', suffixes={'_i', '_v'})\n",
    "merged_df['uid']=merged_df['uid'].astype(str)\n",
    "\n",
    "# note that the length of the merged data frame equaling the len of the smallest \n",
    "# individual dataframe shows that the values being merged on are the same in the\n",
    "# two databases.\n",
    "print(len(i_df))\n",
    "print(len(v_df))\n",
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at data that is 'excellent'\n",
    "excellent_df=merged_df[(merged_df['good_fit_i']=='excellent') & (merged_df['good_fit_v']=='excellent') & \n",
    "                      (merged_df['data_clarity_v']=='well') & (merged_df['data_clarity_i']=='well')]\n",
    "#find combos that are common in this data set\n",
    "excellent_df.groupby(['pre_cre', 'post_cre']).size()\n",
    "#excellent_df[excellent_df['pre_layer']=='5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_sqrt(n):\n",
    "    if n<0:\n",
    "        out = -np.sqrt(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.sqrt(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def pos_log(n):\n",
    "    if n<0:\n",
    "        out = -np.sqrt(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.sqrt(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def plot_hetero(df):\n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "#               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "                              \n",
    "    for var in variables:\n",
    "        f=plt.figure(figsize=(20,10))\n",
    "        # plot data on left\n",
    "        f.add_subplot(131)\n",
    "        sns.regplot(var[0], var[1], data=df, fit_reg=True, color ='k')\n",
    "        plt.xlim([np.min(df[var[0]]), np.max(df[var[0]])])\n",
    "        plt.ylim([np.min(df[var[1]]), np.max(df[var[1]])])\n",
    "        regression=smf.ols(formula='%s ~ %s' %(var[1], var[0]), data=df).fit() \n",
    "        _,_,_,p_unchanged=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "\n",
    "        # plot square root transformed data on right\n",
    "        f.add_subplot(132)\n",
    "        df['sqrt_'+var[0]]=df[var[0]].apply(lambda x: pos_sqrt(x))\n",
    "        df['sqrt_'+var[1]]=df[var[1]].apply(lambda x: pos_sqrt(x))\n",
    "        sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df, fit_reg=True, color ='k')\n",
    "        plt.xlim([np.min(df['sqrt_'+var[0]]), np.max(df['sqrt_'+var[0]])])\n",
    "        plt.ylim([np.min(df['sqrt_'+var[1]]), np.max(df['sqrt_'+var[1]])])\n",
    "        regression=smf.ols(formula='%s ~ %s' %('sqrt_'+var[1], 'sqrt_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_sqrt=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "\n",
    "        \n",
    "        # plot log transformed data on the far right\n",
    "        f.add_subplot(133)\n",
    "        df['log_'+var[0]]=df[var[0]].apply(lambda x: np.log(x))\n",
    "        df['log_'+var[1]]=df[var[1]].apply(lambda x: np.log(x))\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df, fit_reg=True, color ='k')\n",
    "        plt.xlim([np.min(df['log_'+var[0]]), np.max(df['log_'+var[0]])])\n",
    "        plt.ylim([np.min(df['log_'+var[1]]), np.max(df['log_'+var[1]])])\n",
    "        regression=smf.ols(formula='%s ~ %s' %('log_'+var[1], 'log_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_log=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        \n",
    "        print (p_unchanged, p_sqrt, p_log)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_hetero(excellent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To test if the different catagories are the same we must make new catagorical variables\n",
    "# Must get rid of data from the data set we don't want (it might be true that statmodels\n",
    "# skips empty cells but I don't know) and set a catagory value to the rest. \n",
    "def catagory_df(df, catagory_type):\n",
    "    \n",
    "    if catagory_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb'),\n",
    "                ('rorb', 'rorb'),\n",
    "                ('sim1', 'sim1'),\n",
    "                ('tlx3','tlx3'),\n",
    "                ('unknown', 'unknown'))\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2'),\n",
    "               ('2/3', '2/3'),\n",
    "               ('3', '3'),\n",
    "               ('4', '4'),\n",
    "               ('5', '5'),\n",
    "               ('6', '6'))\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "        \n",
    "    #for each cre catagory get a subset make a new column for catagory\n",
    "    new_df=pd.DataFrame()\n",
    "    for value in values: \n",
    "        cat_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "        key=catagory_type+'_catagory'\n",
    "        v=value[0]+'_to_'+value[1]\n",
    "        cat_df[key]=v\n",
    "        #concatenate to whole dataFrame\n",
    "#         print(new_df)\n",
    "#         print(cat_df)\n",
    "        new_df=pd.concat([new_df, cat_df], axis=0, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=False)\n",
    "    return new_df\n",
    "\n",
    "cre_cat_df=catagory_df(excellent_df, 'cre')\n",
    "print(cre_cat_df.groupby('cre_catagory').size())\n",
    "layer_cat_df=catagory_df(excellent_df, 'layer')\n",
    "print(layer_cat_df.groupby('layer_catagory').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is an example on using NRMSE in cre lines.  All conditions will be in a section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#catagorical stats of regressions of different cre lines note that they match plots\n",
    "model=smf.ols(formula='NRMSE_i ~ cre_catagory * NRMSE_v', data=cre_cat_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if the intercept is significantly different\n",
    "int_same_model=smf.ols(formula='NRMSE_i ~ NRMSE_v', data=cre_cat_df).fit() \n",
    "int_diff_model=smf.ols(formula='NRMSE_i ~ cre_catagory + NRMSE_v', data=cre_cat_df).fit()\n",
    "# I don't understand why the p-value is nan here....\n",
    "sm.stats.anova_lm(int_diff_model, int_same_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#note the does not perfectly match the regression plot with all the data because only a subset of data is being used here.\n",
    "int_same_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if slopes are significantly different\n",
    "sm.stats.anova_lm(int_diff_model, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats for all variable with cre line catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_stats(df, catagory_type):\n",
    "    '''\n",
    "    df: pandas DataFrame\n",
    "            should be proccessed from catagory_df\n",
    "    catagory: string\n",
    "        specifies which catagory to apply. Options are 'cre' or 'layer'.\n",
    "    Note: make sure the supplied df corresponds to the supplied catagory_type \n",
    "    '''\n",
    "    if catagory_type=='cre':\n",
    "        col_name=('cre_catagory')\n",
    "        print ('TESTING CRE LINE CATAGORIES')\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('layer_catagory')\n",
    "        print ('TESTING LAYER CATAGORIES')\n",
    "\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "    for var in variables:\n",
    "        # each catagory is allowed independent intercepts and slopes\n",
    "        model=smf.ols(formula='%s ~ %s * %s' %(var[1], col_name, var[0]), data=df).fit()\n",
    "        # all data lumped together\n",
    "        int_same_model=smf.ols(formula='%s ~ %s' %(var[1], var[0]), data=df).fit() \n",
    "        # each catagory is allowed independent intercepts\n",
    "        int_diff_model=smf.ols(formula='%s ~ %s + %s' %(var[1],col_name, var[0]), data=df).fit()\n",
    "        print var\n",
    "        # Note that simplier model must go first!!!!\n",
    "        # check to see if the intercepts are significantly different\n",
    "        print(sm.stats.anova_lm(int_same_model, int_diff_model))\n",
    "        # check to see if slopes are significantly different\n",
    "        print(sm.stats.anova_lm(int_diff_model, model))\n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "do_stats(cre_cat_df, 'cre')\n",
    "do_stats(layer_cat_df, 'layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catagory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def catagory_plots(df, plot_type):\n",
    "    \n",
    "    if plot_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb', 'b'),\n",
    "                ('rorb', 'rorb', 'r'),\n",
    "                ('sim1', 'sim1', 'g'),\n",
    "                ('tlx3','tlx3', 'm'),\n",
    "                ('unknown', 'unknown', 'c'))\n",
    "    elif plot_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2','b'),\n",
    "               ('2/3', '2/3', 'r'),\n",
    "               ('3', '3', 'g'),\n",
    "               ('4', '4', 'm'),\n",
    "               ('5', '5', 'c'),\n",
    "               ('6', '6', 'y'))\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "                              \n",
    "    for var in variables:\n",
    "        fs=15   \n",
    "\n",
    "        plt.figure(figsize=(fs,fs))\n",
    "#         df[var[0]]=np.sqrt(df[var[0]])\n",
    "#         df[var[1]]=np.sqrt(df[var[1]])\n",
    "#         df[var[0]]=df[var[0]].apply(lambda x: pos_sqrt(x))\n",
    "#         df[var[1]]=df[var[1]].apply(lambda x: pos_sqrt(x))\n",
    "        mod = smf.ols(formula='%s ~ %s' % (var[1], var[0]), data=df)\n",
    "        res=mod.fit()\n",
    "        sns.regplot(var[0], var[1], data=df, fit_reg=True, color ='k', \n",
    "                    label='all, n=%i, slope=%f, intercept=%.2E' % (len(df), res.params[var[0]], res.params.Intercept))\n",
    "        for value in values: \n",
    "            plot_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "            mod = smf.ols(formula='%s ~ %s' % (var[1], var[0]), data=plot_df)\n",
    "            res=mod.fit()\n",
    "            print(var, value)\n",
    "            print(res.summary())\n",
    "            print(res.pvalues)\n",
    "            print('\\n')\n",
    "            sns.regplot(var[0], var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "                        label='%s to %s, n=%i, p=%f' % \n",
    "                        (value[0], value[1], len(plot_df), res.pvalues[1]))\n",
    "#             sns.regplot(var[0], var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "#                         label='%s to %s, n=%i, slope=%.2E, int=%.2E' % \n",
    "#                         (value[0], value[1], len(plot_df), res.params[var[0]], res.params.Intercept))\n",
    "        plt.xlim([np.min(df[var[0]]), np.max(df[var[0]])])\n",
    "        plt.ylim([np.min(df[var[1]]), np.max(df[var[1]])])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cre line catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "matplotlib.rc('font', **font)\n",
    "catagory_plots(excellent_df, 'cre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rc('font', **font)\n",
    "catagory_plots(excellent_df, 'layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show images of the voltage and current clamp best fits used in analysis above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "import matplotlib.image as mpimg\n",
    "for p in excellent_df[['image_path_i', 'image_path_v']].iterrows():\n",
    "#    if type(p) is str:\n",
    "    print (p[1].image_path_i)\n",
    "    print (p[1].image_path_v)    \n",
    "#     display(Image(filename=p[1].image_path_i, width=400, height=400))\n",
    "#     display(Image(filename=p[1].image_path_v, width=400, height=400)) \n",
    "    f=plt.figure(figsize=(20,10))\n",
    "    f.add_subplot(121)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_i))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(122)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_v)) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
