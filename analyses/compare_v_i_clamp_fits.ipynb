{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the variable relationships between voltage clamp and current clamp differ for different cre lines or layers?\n",
    "\n",
    "## Objective \n",
    "Determine parameters found by fitting current clamp data can be predicted from from parameters found fitting voltage clamp data (using fits to the average first pulse trace).  If so, do these relationships differ between different cre lines or layers?\n",
    "\n",
    "## Methods\n",
    "a) fit data <br>\n",
    "b) rate the quality of the fit <br>\n",
    "c) choose the goodness of fit one would want to use <br>\n",
    "c) git rid of heteroscedasticity <br>\n",
    "d) break into catagories (i.e. inhibitory/excitatory, cre line, layer) <br>\n",
    "e) test for statistical significance of linear regression <br>\n",
    "f) test for statistical significance that intercepts and slopes of catagories are different <br>\n",
    "\n",
    "## Subquestions addressed to perform this analysis\n",
    "What is the best way to get rid of heteroscedasticity? <br>\n",
    "How good of a fit do we need to assess? <br>\n",
    "\n",
    "\n",
    "\n",
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare voltage clamp and current clamp fits.\n",
    "# Note that these .csv files loaded here have been processed though \"extract_first_pulse_fit_data_from_DB.py\"\n",
    "# \"and catagorize_goodness_of_fit_by_eye.py\"\n",
    "# A fantastic explanation of how to interpret the output and input of linear regression\n",
    "# of different catagories in statsmodels (or R) is at: \n",
    "# https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csv files.\n",
    "i_df=pd.read_csv('ML_connected_iclamp_2018_12_18.csv')\n",
    "v_df=pd.read_csv('ML_connected_vclamp_2018_12_12.csv')\n",
    "i_df['uid']=i_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)\n",
    "v_df['uid']=v_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of wacky Unnamed columns if they exist\n",
    "v_df=v_df[v_df.columns.drop(list(v_df.filter(regex='Unnamed')))]\n",
    "i_df=i_df[i_df.columns.drop(list(i_df.filter(regex='Unnamed')))]\n",
    "i_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge the any sign versus forced sign data frames\n",
    "merged_df = pd.merge(i_df, v_df, on=['uid', 'pre_cell_id', 'post_cell_id', \n",
    "                                     'distance', 'acsf','post_cre', 'pre_cre',\n",
    "                                    'boolean_connection', 'pre_layer', \n",
    "                                     'post_layer'], how='inner', suffixes={'_i', '_v'})\n",
    "merged_df['uid']=merged_df['uid'].astype(str)\n",
    "\n",
    "# note that the length of the merged data frame equaling the len of the smallest \n",
    "# individual dataframe shows that the values being merged on are the same in the\n",
    "# two databases.\n",
    "print(len(i_df))\n",
    "print(len(v_df))\n",
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at data that is 'excellent'\n",
    "excellent_df=merged_df[(merged_df['good_fit_i']=='excellent') & (merged_df['good_fit_v']=='excellent') & \n",
    "                      (merged_df['data_clarity_v']=='well') & (merged_df['data_clarity_i']=='well')]\n",
    "# look at data that is pretty good\n",
    "good_df=merged_df[((merged_df['good_fit_i']=='excellent') | (merged_df['good_fit_i']=='good')) & \n",
    "                       ((merged_df['good_fit_v']=='excellent') | (merged_df['good_fit_v']=='good')) & \n",
    "                       ((merged_df['data_clarity_v']=='well') | (merged_df['data_clarity_v']=='ok')) & \n",
    "                       ((merged_df['data_clarity_i']=='well') | (merged_df['data_clarity_i']=='ok'))]\n",
    "\n",
    "\n",
    "# look at what is in data sets\n",
    "print('excellent fits')\n",
    "print(excellent_df.groupby(['pre_cre', 'post_cre']).size())\n",
    "\n",
    "# print('\\nJust layer 5')\n",
    "# print(excellent_df[excellent_df['pre_layer']=='5'].groupby(['pre_cre', 'post_cre']).size())\n",
    "\n",
    "print('\\ngood fits')\n",
    "print(good_df.groupby(['pre_cre', 'post_cre']).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroscedasticity\n",
    "Look at data and significance tests for heteroscedasticity with different transforms (sqrt and log). <br>\n",
    "Note that in transforms, the amplitude the negative numbers are converted to positive.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_sqrt(n):\n",
    "    if n<0:\n",
    "        out = np.sqrt(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.sqrt(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def pos_log(n):\n",
    "    if n<0:\n",
    "        out = np.log(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.log(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def plot_hetero(df):\n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "                              \n",
    "    for var in variables:\n",
    "        f=plt.figure(figsize=(20,10))\n",
    "        # plot data on left\n",
    "        f.add_subplot(131)\n",
    "        regression=smf.ols(formula='%s ~ %s' %(var[1], var[0]), data=df).fit() \n",
    "        _,_,_,p_unchanged=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot(var[0], var[1], data=df, fit_reg=True, color ='k', label='p=%f' % p_unchanged)\n",
    "        sns.regplot(var[0], var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "        sns.regplot(var[0], var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df[var[0]]), np.max(df[var[0]])])\n",
    "        plt.ylim([np.min(df[var[1]]), np.max(df[var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "        # plot square root transformed data on right\n",
    "        f.add_subplot(132)\n",
    "        df['sqrt_'+var[0]]=df[var[0]].apply(lambda x: pos_sqrt(x))\n",
    "        df['sqrt_'+var[1]]=df[var[1]].apply(lambda x: pos_sqrt(x))\n",
    "        regression=smf.ols(formula='%s ~ %s' %('sqrt_'+var[1], 'sqrt_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_sqrt=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df, color ='k', label='p=%f' % p_sqrt)\n",
    "        sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "        sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df['sqrt_'+var[0]]), np.max(df['sqrt_'+var[0]])])\n",
    "        plt.ylim([np.min(df['sqrt_'+var[1]]), np.max(df['sqrt_'+var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "        # plot log transformed data on the far right\n",
    "        f.add_subplot(133)\n",
    "        df['log_'+var[0]]=df[var[0]].apply(lambda x: pos_log(x))\n",
    "        df['log_'+var[1]]=df[var[1]].apply(lambda x: pos_log(x))\n",
    "        regression=smf.ols(formula='%s ~ %s' %('log_'+var[1], 'log_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_log=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df, fit_reg=True, color ='k', label='p=%f' % p_log)\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df['log_'+var[0]]), np.max(df['log_'+var[0]])])\n",
    "        plt.ylim([np.min(df['log_'+var[1]]), np.max(df['log_'+var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for excellent data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excellent_df=plot_hetero(excellent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at good (larger) data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_df=plot_hetero(good_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhibitory significantly different from excitatory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To test if the different catagories are the same we must make new catagorical variables\n",
    "# Must get rid of data from the data set we don't want (it might be true that statmodels\n",
    "# skips empty cells but I don't know) and set a catagory value to the rest. \n",
    "def catagory_df(df, catagory_type):\n",
    "    \n",
    "    if catagory_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb'),\n",
    "                ('rorb', 'rorb'),\n",
    "                ('sim1', 'sim1'),\n",
    "                ('tlx3','tlx3'),\n",
    "                ('unknown', 'unknown'))\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2'),\n",
    "               ('2/3', '2/3'),\n",
    "               ('3', '3'),\n",
    "               ('4', '4'),\n",
    "               ('5', '5'),\n",
    "               ('6', '6'))\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "        \n",
    "    #for each cre catagory get a subset make a new column for catagory\n",
    "    new_df=pd.DataFrame()\n",
    "    for value in values: \n",
    "        cat_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "        key=catagory_type+'_catagory'\n",
    "        v=value[0]+'_to_'+value[1]\n",
    "        cat_df[key]=v\n",
    "        # concatenate to whole dataFrame\n",
    "#         print(new_df)\n",
    "#         print(cat_df)\n",
    "        new_df=pd.concat([new_df, cat_df], axis=0, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=False)\n",
    "    return new_df\n",
    "\n",
    "cre_cat_df=catagory_df(excellent_df, 'cre')\n",
    "print(cre_cat_df.groupby('cre_catagory').size())\n",
    "layer_cat_df=catagory_df(excellent_df, 'layer')\n",
    "print(layer_cat_df.groupby('layer_catagory').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excellent_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is an example on using NRMSE in cre lines.  All conditions will be in a section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#catagorical stats of regressions of different cre lines note that they match plots\n",
    "model=smf.ols(formula='NRMSE_i ~ cre_catagory * NRMSE_v', data=cre_cat_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if the intercept is significantly different\n",
    "int_same_model=smf.ols(formula='NRMSE_i ~ NRMSE_v', data=cre_cat_df).fit() \n",
    "int_diff_model=smf.ols(formula='NRMSE_i ~ cre_catagory + NRMSE_v', data=cre_cat_df).fit()\n",
    "# I don't understand why the p-value is nan here....\n",
    "sm.stats.anova_lm(int_diff_model, int_same_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#note the does not perfectly match the regression plot with all the data because only a subset of data is being used here.\n",
    "int_same_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if slopes are significantly different\n",
    "sm.stats.anova_lm(int_diff_model, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats for all variable with cre line catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_stats(df, catagory_type):\n",
    "    '''\n",
    "    df: pandas DataFrame\n",
    "            should be proccessed from catagory_df\n",
    "    catagory: string\n",
    "        specifies which catagory to apply. Options are 'cre' or 'layer'.\n",
    "    Note: make sure the supplied df corresponds to the supplied catagory_type \n",
    "    '''\n",
    "    if catagory_type=='cre':\n",
    "        col_name=('cre_catagory')\n",
    "        print ('TESTING CRE LINE CATAGORIES')\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('layer_catagory')\n",
    "        print ('TESTING LAYER CATAGORIES')\n",
    "\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "    for var in variables:\n",
    "        # each catagory is allowed independent intercepts and slopes\n",
    "        model=smf.ols(formula='%s ~ %s * %s' %('log_'+var[1], col_name, 'log_'+var[0]), data=df).fit()\n",
    "        # all data lumped together\n",
    "        int_same_model=smf.ols(formula='%s ~ %s' %('log_'+var[1], 'log_'+var[0]), data=df).fit() \n",
    "        # each catagory is allowed independent intercepts\n",
    "        int_diff_model=smf.ols(formula='%s ~ %s + %s' %('log_'+var[1],col_name, 'log_'+var[0]), data=df).fit()\n",
    "        print var\n",
    "        # Note that simplier model must go first!!!!\n",
    "        # check to see if the intercepts are significantly different\n",
    "        print('check if intercepts are different')\n",
    "        print(sm.stats.anova_lm(int_same_model, int_diff_model))\n",
    "        # check to see if slopes are significantly different\n",
    "        print('check if slopes are different')\n",
    "        print(sm.stats.anova_lm(int_diff_model, model))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "do_stats(cre_cat_df, 'cre')\n",
    "do_stats(layer_cat_df, 'layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catagory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def catagory_plots(df, plot_type):\n",
    "    \n",
    "    if plot_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb', 'b'),\n",
    "                ('rorb', 'rorb', 'r'),\n",
    "                ('sim1', 'sim1', 'g'),\n",
    "                ('tlx3','tlx3', 'm'),\n",
    "                ('unknown', 'unknown', 'c'))\n",
    "    elif plot_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2','b'),\n",
    "               ('2/3', '2/3', 'r'),\n",
    "               ('3', '3', 'g'),\n",
    "               ('4', '4', 'm'),\n",
    "               ('5', '5', 'c'),\n",
    "               ('6', '6', 'y'))\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "                              \n",
    "    for var in variables:\n",
    "        fs=15   \n",
    "\n",
    "        plt.figure(figsize=(fs,fs))\n",
    "        mod = smf.ols(formula='%s ~ %s' % ('log_'+var[1], 'log_'+var[0]), data=df)\n",
    "        res=mod.fit()\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df, fit_reg=True, color ='k', \n",
    "                    label='all, n=%i, slope=%f, intercept=%.2E' % \n",
    "                    (len(df), res.params['log_'+var[0]], res.params.Intercept))\n",
    "        for value in values: \n",
    "            plot_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "            mod = smf.ols(formula='%s ~ %s' % ('log_'+var[1], 'log_'+var[0]), data=plot_df)\n",
    "            res=mod.fit()\n",
    "            print(var, value)\n",
    "            print(res.summary())\n",
    "            print(res.pvalues)\n",
    "            print('\\n')\n",
    "            sns.regplot('log_'+var[0], 'log_'+var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "                        label='%s to %s, n=%i, p=%f' % \n",
    "                        (value[0], value[1], len(plot_df), res.pvalues[1]))\n",
    "#             sns.regplot(var[0], var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "#                         label='%s to %s, n=%i, slope=%.2E, int=%.2E' % \n",
    "#                         (value[0], value[1], len(plot_df), res.params[var[0]], res.params.Intercept))\n",
    "        plt.xlim([np.min(df['log_'+var[0]]), np.max(df['log_'+var[0]])])\n",
    "        plt.ylim([np.min(df['log_'+var[1]]), np.max(df['log_'+var[1]])])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cre line catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "matplotlib.rc('font', **font)\n",
    "catagory_plots(excellent_df, 'cre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rc('font', **font)\n",
    "catagory_plots(excellent_df, 'layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show images of the voltage and current clamp best fits used in analysis above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "import matplotlib.image as mpimg\n",
    "for p in excellent_df[['image_path_i', 'image_path_v']].iterrows():\n",
    "#    if type(p) is str:\n",
    "    print (p[1].image_path_i)\n",
    "    print (p[1].image_path_v)    \n",
    "#     display(Image(filename=p[1].image_path_i, width=400, height=400))\n",
    "#     display(Image(filename=p[1].image_path_v, width=400, height=400)) \n",
    "    f=plt.figure(figsize=(20,10))\n",
    "    f.add_subplot(121)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_i))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(122)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_v)) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
