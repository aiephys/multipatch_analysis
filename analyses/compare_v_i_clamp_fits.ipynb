{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can voltage clamp be used to predict current clamp parameters?\n",
    "Corinne Teeter\n",
    "\n",
    "### Objective \n",
    "Determine parameters found by fitting current clamp data can be predicted from from parameters found fitting voltage clamp data (using fits to the average first pulse trace).  If so, do these relationships differ between different cre lines or layers?\n",
    "\n",
    "### Methods\n",
    "a) Fit the average of the first pulse voltage clamp and current clamp data. <br>\n",
    "b) Rate the quality of the fit by eye. <br>\n",
    "c) Remove heteroscedasticity. <br>\n",
    "d) Break into catagories (i.e. inhibitory/excitatory, cre line, layer). <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test for statistical significance of linear regression. <br>\n",
    "e) Test for statistical significance that intercepts and slopes of catagories with significant regressions are different. <br>\n",
    "\n",
    "### Subquestions addressed in this analysis\n",
    "What is the best way to get rid of heteroscedasticity? <br>\n",
    "How good does the fit need to be to assess statistical differences? <br>\n",
    "\n",
    "### Caveats\n",
    "In many of the fits, it does not look like rise is fit well with one exponential.  This throws off the location of the amplitude.\n",
    "\n",
    "### Discussion/remaining questions\n",
    "Think about why NRMSE, amp and rise time would be heteroscedastic. <br>\n",
    "What do the different predictive relationships between different catagories mean?\n",
    "\n",
    "### Potenial future directions\n",
    "Use double exponentials in fit to clean up analysis\n",
    "\n",
    "\n",
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that these .csv files loaded here have been processed though \"extract_first_pulse_fit_data_from_DB.py\"\n",
    "# \"and catagorize_goodness_of_fit_by_eye.py\"\n",
    "# A fantastic explanation of how to interpret the output and input of linear regression\n",
    "# of different catagories in statsmodels (or R) is at: \n",
    "# https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csv files.\n",
    "i_df=pd.read_csv('ML_connected_iclamp_2018_12_18.csv')\n",
    "v_df=pd.read_csv('ML_connected_vclamp_2018_12_12.csv')\n",
    "i_df['uid']=i_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)\n",
    "v_df['uid']=v_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of wacky Unnamed columns if they exist\n",
    "v_df=v_df[v_df.columns.drop(list(v_df.filter(regex='Unnamed')))]\n",
    "i_df=i_df[i_df.columns.drop(list(i_df.filter(regex='Unnamed')))]\n",
    "i_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge voltage and current clamp data frames\n",
    "merged_df = pd.merge(i_df, v_df, on=['uid', 'pre_cell_id', 'post_cell_id', \n",
    "                                     'distance', 'acsf','post_cre', 'pre_cre',\n",
    "                                    'boolean_connection', 'pre_layer', \n",
    "                                     'post_layer'], how='inner', suffixes={'_i', '_v'})\n",
    "merged_df['uid']=merged_df['uid'].astype(str)\n",
    "\n",
    "# note that the length of the merged data frame equaling the len of the smallest \n",
    "# individual dataframe shows that the values being merged on are the same in the\n",
    "# two databases.\n",
    "print(len(i_df))\n",
    "print(len(v_df))\n",
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets: excellent versus well fit data\n",
    "The quality of the fit was assessed by eye (See images at the end of the document for examples.).  More data will be included if the 'well fit' data are used in addition to the 'excellent fit' data.  However it is unclear if including well fit data will benifit the analysis as it may add  noise.  Throughout, results on the excellent versus well fit data will be shown.  The decay tau values are not yet well fit and many are hitting the boundries.  Here, the values hitting the boundry in vclamp are removed, however, this does not resolve the issue, as in general, decay tau is not well fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the data that is 'excellent'\n",
    "excellent_df=merged_df[(merged_df['good_fit_i']=='excellent') & (merged_df['good_fit_v']=='excellent') & \n",
    "                      (merged_df['data_clarity_v']=='well') & (merged_df['data_clarity_i']=='well')]\n",
    "# merge the data that is pretty good\n",
    "good_df=merged_df[((merged_df['good_fit_i']=='excellent') | (merged_df['good_fit_i']=='good')) & \n",
    "                       ((merged_df['good_fit_v']=='excellent') | (merged_df['good_fit_v']=='good')) & \n",
    "                       ((merged_df['data_clarity_v']=='well') | (merged_df['data_clarity_v']=='ok')) & \n",
    "                       ((merged_df['data_clarity_i']=='well') | (merged_df['data_clarity_i']=='ok'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroscedasticity\n",
    "Heteroscedasticity is when the regression errors systematically increase or decrease with the variables.  It can be seen by eye in this data.  Here, I explore if two data transforms will abolish heteroscedasticity.  Whiteâ€™s Lagrange Multiplier Test for Heteroscedasticity provides a p-value to assess whether the heteroscedasticity is statistically significant. Note that in transforms of the amplitude data, negative numbers are converted to positive.   \n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_sqrt(n):\n",
    "    if n<0:\n",
    "        out = np.sqrt(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.sqrt(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def pos_log(n):\n",
    "    if n<0:\n",
    "        out = np.log(np.abs(n))\n",
    "    if n>=0:\n",
    "        out = np.log(n)\n",
    "    if np.isnan(n):\n",
    "        return np.nan\n",
    "    return out\n",
    "\n",
    "def plot_hetero(df):\n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "    def plotting(var, df): \n",
    "        # plot data on left\n",
    "        f.add_subplot(131)\n",
    "        regression=smf.ols(formula='%s ~ %s' %(var[1], var[0]), data=df).fit() \n",
    "        _,_,_,p_unchanged=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot(var[0], var[1], data=df, fit_reg=True, color ='k', label='p=%f' % p_unchanged)\n",
    "#         sns.regplot(var[0], var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "#         sns.regplot(var[0], var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df[var[0]]), np.max(df[var[0]])])\n",
    "        plt.ylim([np.min(df[var[1]]), np.max(df[var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "        # plot square root transformed data on right\n",
    "        f.add_subplot(132)\n",
    "        df['sqrt_'+var[0]]=df[var[0]].apply(lambda x: pos_sqrt(x))\n",
    "        df['sqrt_'+var[1]]=df[var[1]].apply(lambda x: pos_sqrt(x))\n",
    "        regression=smf.ols(formula='%s ~ %s' %('sqrt_'+var[1], 'sqrt_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_sqrt=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df, color ='k', label='p=%f' % p_sqrt)\n",
    "#         sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "#         sns.regplot('sqrt_'+var[0], 'sqrt_'+var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df['sqrt_'+var[0]]), np.max(df['sqrt_'+var[0]])])\n",
    "        plt.ylim([np.min(df['sqrt_'+var[1]]), np.max(df['sqrt_'+var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "        # plot log transformed data on the far right\n",
    "        f.add_subplot(133)\n",
    "        df['log_'+var[0]]=df[var[0]].apply(lambda x: pos_log(x))\n",
    "        df['log_'+var[1]]=df[var[1]].apply(lambda x: pos_log(x))\n",
    "        regression=smf.ols(formula='%s ~ %s' %('log_'+var[1], 'log_'+var[0]), data=df).fit() \n",
    "        _,_,_,p_log=statsmodels.stats.diagnostic.het_white(regression.resid, regression.model.exog)\n",
    "        sns.regplot('log_'+var[0], 'log_'+var[1], data=df, fit_reg=True, color ='k', label='p=%f' % p_log)\n",
    "#         sns.regplot('log_'+var[0], 'log_'+var[1], data=df[df['syn_excitation_v']=='in'], fit_reg=True, color ='r')\n",
    "#         sns.regplot('log_'+var[0], 'log_'+var[1], data=df[df['syn_excitation_v']=='ex'], fit_reg=True, color ='g')\n",
    "        plt.xlim([np.min(df['log_'+var[0]]), np.max(df['log_'+var[0]])])\n",
    "        plt.ylim([np.min(df['log_'+var[1]]), np.max(df['log_'+var[1]])])\n",
    "        plt.legend()\n",
    "\n",
    "    for var in variables:\n",
    "        f=plt.figure(figsize=(20,6))\n",
    "        if var==('decay_tau_v', 'decay_tau_i'):\n",
    "            plotting(var,df[df['decay_tau_v']<.49])\n",
    "        else:\n",
    "            plotting(var, df)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroscedasticity in 'excellent fit' data set\n",
    "### Results\n",
    "Amplitude, rise tau, and NMRSE require log transform to remove heteroscedasticity (p-value is less significant).  Latency and decay tau do not require a transform.  The following analysis testing catagorical regression significance and differences will incorporate the necessary transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excellent_df=plot_hetero(excellent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 'well fit' (larger) data set\n",
    "### Results\n",
    "Similar to 'excellent fit' data set, NRMSE, rise_time, and amplitude require log transforms to remove heteroscedasticity and decay tau does not require a transform.  The one difference here is that the latency value shows a statistically significant p-value for heteroscedasticity when there is no transform, non significant with a sqrt transform and sigfificant again with a log transform.  I am going to ignore this deviation from the 'excellent fit' data since the data does not look blatently heteroscedastic, the p-value is only passes 95% significance, and it may be the case that one value has triggered the significant p-value here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_df=plot_hetero(good_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to test if the data can be fit via a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def regression_significance(df_list, catagory_type, data_type='', \n",
    "                            variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "                                       ('amp_v', 'amp_i'),\n",
    "                                       ('rise_time_v', 'rise_time_i'),\n",
    "                                       ('latency_v', 'latency_i'),\n",
    "                                       ('decay_tau_v', 'decay_tau_i'))):\n",
    "    \"\"\"This test if the variables can be fit with regression lines. \n",
    "    Should later be used to make catagory DataFrames for testing \n",
    "    individual statistical significance.\"\"\"\n",
    "    font={'size':22}\n",
    "    matplotlib.rc('font', **font)\n",
    "    df_num=len(df_list)\n",
    "    font={'size':22/df_num}\n",
    "    matplotlib.rc('font', **font)\n",
    "\n",
    "    \n",
    "    if catagory_type=='excitation':\n",
    "        col_name=('syn_excitation_v', 'syn_excitation_v')\n",
    "        values=(('ex', 'ex', 'b'),\n",
    "                ('in', 'in', 'r'))\n",
    "        \n",
    "    elif catagory_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb', 'b'),\n",
    "                ('rorb', 'rorb', 'r'),\n",
    "                ('sim1', 'sim1', 'g'),\n",
    "                ('tlx3','tlx3', 'm'),\n",
    "                ('unknown', 'unknown', 'c'))\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2','b'),\n",
    "               ('2/3', '2/3', 'r'),\n",
    "               ('3', '3', 'g'),\n",
    "               ('4', '4', 'm'),\n",
    "               ('5', '5', 'c'),\n",
    "               ('6', '6', 'y'))\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "#     variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "#                ('amp_v', 'amp_i'),\n",
    "#                ('rise_time_v', 'rise_time_i'),\n",
    "#                ('latency_v', 'latency_i'),\n",
    "#                ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "    fs=20.                  \n",
    "    def plotting(var, df_list):\n",
    "        for ii,df in enumerate(df_list):\n",
    "            plt.subplot(1,df_num, ii+1)\n",
    "            mod = smf.ols(formula='%s ~ %s' % (data_type+var[1], data_type+var[0]), data=df)\n",
    "            res=mod.fit()\n",
    "            sns.regplot(data_type+var[0], data_type+var[1], data=df, fit_reg=True, color ='k', \n",
    "                            label='all, n=%i, p_slope=%f' % \n",
    "                            (len(df), res.pvalues[1]))\n",
    "            for value in values: \n",
    "                plot_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "                mod = smf.ols(formula='%s ~ %s' % (data_type+var[1], data_type+var[0]), data=plot_df)\n",
    "                res=mod.fit()\n",
    "                sns.regplot(data_type+var[0], data_type+var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "                            label='%s to %s, n=%i, slope=%f, p_slope=%f' % \n",
    "                            (value[0], value[1], len(plot_df),res.params[1], res.pvalues[1]))\n",
    "    #             sns.regplot(var[0], var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "    #                         label='%s to %s, n=%i, slope=%.2E, int=%.2E' % \n",
    "    #                         (value[0], value[1], len(plot_df), res.params[var[0]], res.params.Intercept))\n",
    "            plt.xlim([np.min(df[data_type+var[0]]), np.max(df[data_type+var[0]])])\n",
    "            plt.ylim([np.min(df[data_type+var[1]]), np.max(df[data_type+var[1]])])\n",
    "            plt.legend()\n",
    "    \n",
    "    for var in variables:\n",
    "        plt.figure(figsize=(fs,fs/df_num))\n",
    "        if var==('decay_tau_v', 'decay_tau_i'):\n",
    "            sub_df_list=[]\n",
    "            for df in df_list:\n",
    "                new=df[df['decay_tau_v']<.49]\n",
    "                sub_df_list.append(new)\n",
    "            plotting(var,sub_df_list)\n",
    "        else:\n",
    "            plotting(var, df_list)        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "# regression_significance([excellent_df, good_df], 'excitation', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "#                ('amp_v', 'amp_i'),\n",
    "#                ('rise_time_v', 'rise_time_i')))\n",
    "# regression_significance([excellent_df, good_df], 'excitation', data_type='', variables=(\n",
    "#                ('latency_v', 'latency_i'),\n",
    "#                ('decay_tau_v', 'decay_tau_i')))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to test if linear regressions of different catagories are statistically different\n",
    "## Would like to split this up to excellent and well on right and left and add significance to plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_sig_diff(df, catagory_type, data_type='', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "                                       ('amp_v', 'amp_i'),\n",
    "                                       ('rise_time_v', 'rise_time_i'),\n",
    "                                       ('latency_v', 'latency_i'),\n",
    "                                       ('decay_tau_v', 'decay_tau_i'))):\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame\n",
    "        should be proccessed from catagory_df\n",
    "    catagory: string\n",
    "        specifies which catagory to apply. Options are 'cre','layer', 'excitation'.\n",
    "    data_type: string\n",
    "        specifies which data transform you are using.\n",
    "        options: ''       non transformed data\n",
    "                 'log_'   sqrt of data (negative values made positive before transform)\n",
    "                 'sqrt_'  log of data (negative values made positive before transform)\n",
    "    Note: make sure the supplied df corresponds to the supplied catagory_type \n",
    "    \"\"\"\n",
    "\n",
    "    if catagory_type=='excitation':\n",
    "        col_name='syn_excitation_v'\n",
    "        print ('TESTING EXCITATORY AND INHIBITION')\n",
    "    elif catagory_type=='cre':\n",
    "        col_name='cre_catagory'\n",
    "        print ('TESTING CRE LINE CATAGORIES')\n",
    "    elif catagory_type=='layer':\n",
    "        col_name='layer_catagory'\n",
    "        print ('TESTING LAYER CATAGORIES')\n",
    "\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "        \n",
    "    for var in variables:\n",
    "        # each catagory is allowed independent intercepts and slopes\n",
    "        model=smf.ols(formula='%s ~ %s * %s' %(data_type+var[1], col_name, data_type+var[0]), data=df).fit()\n",
    "        # all data lumped together\n",
    "        int_same_model=smf.ols(formula='%s ~ %s' %(data_type+var[1], data_type+var[0]), data=df).fit() \n",
    "        # each catagory is allowed independent intercepts\n",
    "        int_diff_model=smf.ols(formula='%s ~ %s + %s' %(data_type+var[1],col_name, data_type+var[0]), data=df).fit()\n",
    "\n",
    "        print var\n",
    "        # Note that simplier model must go first in the sm.satats.anova_lm!!!!\n",
    "        # check to see if the intercepts are significantly different\n",
    "        print('check if intercepts are different')\n",
    "        print(sm.stats.anova_lm(int_same_model, int_diff_model))\n",
    "        # check to see if slopes are significantly different\n",
    "        print('check if slopes are different')\n",
    "        print(sm.stats.anova_lm(int_diff_model, model))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # plot catagories\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for value in df[col_name].unique(): \n",
    "            plot_df=df[df[col_name]==value]\n",
    "#             mod = smf.ols(formula='%s ~ %s' % (data_type+var[1], data_type+var[0]), data=plot_df)\n",
    "#             res=mod.fit()\n",
    "            sns.regplot(data_type+var[0], data_type+var[1], data=plot_df, fit_reg=True, \n",
    "                        label='%s, n=%i' % (value, len(plot_df)))\n",
    "        plt.xlim([np.min(df[data_type+var[0]]), np.max(df[data_type+var[0]])])\n",
    "        plt.ylim([np.min(df[data_type+var[1]]), np.max(df[data_type+var[1]])])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        \n",
    "# cat_sig_diff(cre_cat_df, 'cre', data_type='sqrt_')\n",
    "# cat_sig_diff(layer_cat_df, 'layer', data_type='sqrt_')\n",
    "# cat_sig_diff(excellent_df, 'excitation', data_type='log_')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to reduce DataFrames to catagories to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_catagory_df(df, catagory_type):\n",
    "    ''' To test if the different catagories are the same we must make new catagorical variables\n",
    "    Must get rid of data from the data set we don't want (it might be true that statmodels\n",
    "    skips empty cells but I don't know) and set a catagory value to the rest.'''\n",
    "    \n",
    "    if catagory_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb'),\n",
    "#                ('rorb', 'rorb'),\n",
    "                ('sim1', 'sim1'),\n",
    "#                ('tlx3','tlx3'),\n",
    "                ('unknown', 'unknown'))\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2'),\n",
    "               ('2/3', '2/3'),\n",
    "#               ('3', '3'),\n",
    "               ('4', '4'),\n",
    "               ('5', '5'))\n",
    "#               ('6', '6'))\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "        \n",
    "    #for each cre catagory get a subset make a new column for catagory\n",
    "    new_df=pd.DataFrame()\n",
    "    for value in values: \n",
    "        cat_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "        key=catagory_type+'_catagory'\n",
    "        v=value[0]+'_to_'+value[1]\n",
    "        cat_df[key]=v\n",
    "        # concatenate to whole dataFrame\n",
    "#         print(new_df)\n",
    "#         print(cat_df)\n",
    "        new_df=pd.concat([new_df, cat_df], axis=0, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excitation\n",
    "\n",
    "### Results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance of regression for excitation catagories\n",
    "#### Results\n",
    "All parameters except decau tau have statistically significant regression lines for inhibitory and excitatory catagories for both 'excellent fit' data (shown on left) and 'well fit' data (shown on right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression_significance([excellent_df, good_df], 'excitation', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "regression_significance([excellent_df, good_df], 'excitation', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i')))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are excitatory and inhibitory linear regressions significantly different\n",
    "\n",
    "### Results \n",
    "NRMSE is not significantly different. <br>\n",
    "Amplitude is significantly different. <br>\n",
    "Rise_time is significantly different. <br>\n",
    "Latency intercept is significantly difference but not the slope.  Not sure what the interpretation for this would be. \n",
    "\n",
    "## 'Excellent fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(excellent_df, 'excitation', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(excellent_df, 'excitation', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))\n",
    "# not doing decay tau as it doesnt is not related\n",
    "#               ('decay_tau_v', 'decay_tau_i')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Well fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(good_df, 'excitation', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(good_df, 'excitation', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))\n",
    "# not doing decay tau as it doesnt is not related\n",
    "#               ('decay_tau_v', 'decay_tau_i')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cre lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cre line groups available in the data\n",
    "### Results\n",
    "pv to pv, sim1 to sim1, and unknown to unknown have enough points in both excellent and good fits.\n",
    "\n",
    "rorb to rorb and tlx3 to tlx3 are on the cusp with 6 data points each in the excellent data set and only a couple are added with the good data set.  Not sure whether these will be enough to add significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at what is in data sets\n",
    "print('excellent fits')\n",
    "print(excellent_df.groupby(['pre_cre', 'post_cre']).size())\n",
    "\n",
    "print('\\ngood fits')\n",
    "print(good_df.groupby(['pre_cre', 'post_cre']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance of regression for cre-line catagories\n",
    "#### Results\n",
    "NRMSE <b>\n",
    "pv to pv, sim1 to sim1, and unknown to unknown have a statistically significant slope in both 'excellent' and 'well' fit data.  Rorb to rorb is not statistically significant in either case and tlx3 to tlx3 is significant in 'excellent' and not in 'well'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "regression_significance([excellent_df, good_df], 'cre', data_type='log_', variables=(\n",
    "               ('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "regression_significance([excellent_df, good_df], 'cre', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reduced catagory DataFrame for cre-lines based on regression significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cre_cat_excellent_df=create_catagory_df(excellent_df, 'cre')\n",
    "print(cre_cat_excellent_df.groupby('cre_catagory').size())\n",
    "cre_cat_good_df=create_catagory_df(good_df, 'cre')\n",
    "print(cre_cat_good_df.groupby('cre_catagory').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are cre-lines with statistically significant regression lines significantly different from one another?\n",
    "\n",
    "### 'Excellent fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(cre_cat_excellent_df, 'cre', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(cre_cat_excellent_df, 'cre', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Well fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(cre_cat_good_df, 'cre', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(cre_cat_good_df, 'cre', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer catagories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer groups available in the data\n",
    "It appears adding the 'good' fits might add significance to the smaller groups.  For example layer 6 to layer 6 is doubled.???????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at what is in data sets\n",
    "print('excellent fits')\n",
    "print(excellent_df.groupby(['pre_layer', 'post_layer']).size())\n",
    "\n",
    "print('\\ngood fits')\n",
    "print(good_df.groupby(['pre_layer', 'post_layer']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression significance for different layer catagories\n",
    "### Results\n",
    "'Excellent fit' data shown on the left and 'well fit' data on the right.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "regression_significance([excellent_df, good_df], 'layer', data_type='log_', variables=(\n",
    "               ('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "regression_significance([excellent_df, good_df], 'layer', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reduced catagory DataFrame for layers based on regression significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_cat_excellent_df=create_catagory_df(excellent_df, 'layer')\n",
    "print(layer_cat_excellent_df.groupby('layer_catagory').size())\n",
    "layer_cat_good_df=create_catagory_df(good_df, 'layer')\n",
    "print(layer_cat_good_df.groupby('layer_catagory').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are layers with statistically significant regression lines significantly different from one another?\n",
    "\n",
    "### 'Excellent fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(layer_cat_excellent_df, 'layer', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(layer_cat_excellent_df, 'layer', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Well fit' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_sig_diff(layer_cat_good_df, 'layer', data_type='log_', variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i')))\n",
    "cat_sig_diff(layer_cat_good_df, 'layer', data_type='', variables=(\n",
    "               ('latency_v', 'latency_i'),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is an example on using NRMSE in cre lines.  All conditions will be in a section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#catagorical stats of regressions of different cre lines note that they match plots\n",
    "model=smf.ols(formula='NRMSE_i ~ cre_catagory * NRMSE_v', data=cre_cat_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if the intercept is significantly different\n",
    "int_same_model=smf.ols(formula='NRMSE_i ~ NRMSE_v', data=cre_cat_df).fit() \n",
    "int_diff_model=smf.ols(formula='NRMSE_i ~ cre_catagory + NRMSE_v', data=cre_cat_df).fit()\n",
    "# I don't understand why the p-value is nan here....\n",
    "sm.stats.anova_lm(int_diff_model, int_same_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#note the does not perfectly match the regression plot with all the data because only a subset of data is being used here.\n",
    "int_same_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if slopes are significantly different\n",
    "sm.stats.anova_lm(int_diff_model, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show images of the voltage and current clamp best fits used in analysis above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "import matplotlib.image as mpimg\n",
    "for p in excellent_df[['image_path_i', 'image_path_v']].iterrows():\n",
    "#    if type(p) is str:\n",
    "    print (p[1].image_path_i)\n",
    "    print (p[1].image_path_v)    \n",
    "#     display(Image(filename=p[1].image_path_i, width=400, height=400))\n",
    "#     display(Image(filename=p[1].image_path_v, width=400, height=400)) \n",
    "    f=plt.figure(figsize=(20,10))\n",
    "    f.add_subplot(121)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_i))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(122)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_v)) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
