{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare voltage clamp and current clamp fits.\n",
    "# Note that these .csv files loaded here have been process though \"extract_first_pulse_fit_data_from_DB.py\"\n",
    "# \"and catagorize_goodness_of_fit_by_eye.py\"\n",
    "# A fantastic explanation of how to interpret the output and input of linear regression\n",
    "# of different catagories in statsmodels (or R) is at: \n",
    "# https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csv files.\n",
    "i_df=pd.read_csv('ML_connected_iclamp_2018_12_18.csv')\n",
    "v_df=pd.read_csv('ML_connected_vclamp_2018_12_12.csv')\n",
    "i_df['uid']=i_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)\n",
    "v_df['uid']=v_df.apply(lambda row: \"%.3f\" % float(row.uid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of wacky Unnamed columns if they exist\n",
    "v_df=v_df[v_df.columns.drop(list(v_df.filter(regex='Unnamed')))]\n",
    "i_df=i_df[i_df.columns.drop(list(i_df.filter(regex='Unnamed')))]\n",
    "i_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge the any sign versus forced sign data frames\n",
    "merged_df = pd.merge(i_df, v_df, on=['uid', 'pre_cell_id', 'post_cell_id', \n",
    "                                     'distance', 'acsf','post_cre', 'pre_cre',\n",
    "                                    'boolean_connection', 'pre_layer', 'post_layer'], how='inner', suffixes={'_i', '_v'})\n",
    "merged_df['uid']=merged_df['uid'].astype(str)\n",
    "\n",
    "# note that the length of the merged data frame equaling the len of the smallest \n",
    "# individual dataframe shows that the values being merged on are the same in the\n",
    "# two databases.\n",
    "print(len(i_df))\n",
    "print(len(v_df))\n",
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at data that is 'excellent'\n",
    "excellent_df=merged_df[(merged_df['good_fit_i']=='excellent') & (merged_df['good_fit_v']=='excellent') & \n",
    "                      (merged_df['data_clarity_v']=='well') & (merged_df['data_clarity_i']=='well')]\n",
    "#find combos that are common in this data set\n",
    "excellent_df.groupby(['pre_cre', 'post_cre']).size()\n",
    "#excellent_df[excellent_df['pre_layer']=='5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basic_plots(df):\n",
    "    \n",
    "    sns.regplot('NRMSE_v', 'NRMSE_i', data=df, fit_reg=True)\n",
    "    plt.show()\n",
    "    sns.regplot('amp_v', 'amp_i', data=df, fit_reg=True)\n",
    "    plt.show()\n",
    "    sns.regplot('rise_time_v', 'rise_time_i', data=df, fit_reg=True)\n",
    "    plt.show()\n",
    "    sns.regplot('latency_v', 'latency_i', data=df, fit_reg=True)\n",
    "    plt.show()\n",
    "    sns.regplot('decay_tau_v', 'decay_tau_i', data=df, fit_reg=True)\n",
    "    plt.show()\n",
    "    \n",
    "def cre_plots(df, plot_type):\n",
    "    \n",
    "    if plot_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb', 'b'),\n",
    "                ('rorb', 'rorb', 'r'),\n",
    "                ('sim1', 'sim1', 'g'),\n",
    "                ('tlx3','tlx3', 'm'),\n",
    "                ('unknown', 'unknown', 'c'))\n",
    "    elif plot_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2','b'),\n",
    "               ('2/3', '2/3', 'r'),\n",
    "               ('3', '3', 'g'),\n",
    "               ('4', '4', 'm'),\n",
    "               ('5', '5', 'c'),\n",
    "               ('6', '6', 'y'))\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    variables=(('NRMSE_v', 'NRMSE_i'),\n",
    "               ('amp_v', 'amp_i'),\n",
    "               ('rise_time_v', 'rise_time_i'),\n",
    "               ('latency_v', 'latency_i'),\n",
    "               ('decay_tau_v', 'decay_tau_i'))\n",
    "\n",
    "               \n",
    "               \n",
    "#     for var in variables:\n",
    "    if True:\n",
    "        var =variables[0]\n",
    "        fs=15   \n",
    "\n",
    "        plt.figure(figsize=(fs,fs))\n",
    "        mod = smf.ols(formula='%s ~ %s' % (var[1], var[0]), data=df)\n",
    "        res=mod.fit()\n",
    "        sns.regplot(var[0], var[1], data=df, fit_reg=True, color ='k', \n",
    "                    label='all, n=%i, slope=%f, intercept=%.2E' % (len(df), res.params[var[0]], res.params.Intercept))\n",
    "        for value in values: \n",
    "            plot_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "            mod = smf.ols(formula='%s ~ %s' % (var[1], var[0]), data=plot_df)\n",
    "            res=mod.fit()\n",
    "            sns.regplot(var[0], var[1], data=plot_df, fit_reg=True, color=value[2], \n",
    "                        label='%s to %s, n=%i, slope=%.2E, int=%.2E' % \n",
    "                        (value[0], value[1], len(plot_df), res.params[var[0]], res.params.Intercept))\n",
    "        plt.xlim([np.min(df[var[0]]), np.max(df[var[0]])])\n",
    "        plt.ylim([np.min(df[var[1]]), np.max(df[var[1]])])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To test if the different catagories are the same we must make new catagorical variables\n",
    "# Must get rid of data from the data set we don't want (it might be true that statmodels\n",
    "# skips empty cells but I don't know) and set a catagory value to the rest. \n",
    "def catagory_df(df, catagory_type):\n",
    "    \n",
    "    if catagory_type=='cre':\n",
    "        col_name=('pre_cre', 'post_cre')\n",
    "        values=(('pvalb', 'pvalb'),\n",
    "                ('rorb', 'rorb'),\n",
    "                ('sim1', 'sim1'),\n",
    "                ('tlx3','tlx3'),\n",
    "                ('unknown', 'unknown'))\n",
    "    elif catagory_type=='layer':\n",
    "        col_name=('pre_layer', 'post_layer')\n",
    "        values=(('2', '2','b'),\n",
    "               ('2/3', '2/3', 'r'),\n",
    "               ('3', '3', 'g'),\n",
    "               ('4', '4', 'm'),\n",
    "               ('5', '5', 'c'),\n",
    "               ('6', '6', 'y'))\n",
    "    else:\n",
    "        raise Exception('catagory doesnt exist')\n",
    "        \n",
    "    #for each cre catagory get a subset make a new column for catagory\n",
    "    new_df=pd.DataFrame()\n",
    "    for value in values: \n",
    "        cat_df=df[(df[col_name[0]]==value[0]) & (df[col_name[1]]==value[1])]\n",
    "        key=catagory_type+'_catagory'\n",
    "        v=value[0]+'_to_'+value[1]\n",
    "        cat_df[key]=v\n",
    "        #concatenate to whole dataFrame\n",
    "#         print(new_df)\n",
    "#         print(cat_df)\n",
    "        new_df=pd.concat([new_df, cat_df], axis=0, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=False)\n",
    "    return new_df\n",
    "\n",
    "cre_cat_df=catagory_df(excellent_df, 'cre')\n",
    "print(cre_cat_df.groupby('cre_catagory').size())\n",
    "layer_cat_df=catagory_df(excellent_df, 'layer')\n",
    "print(layer_cat_df.groupby('layer_catagory').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#catagorical stats of regressions of different cre lines note that they match plots\n",
    "model=smf.ols(formula='NRMSE_i ~ cre_catagory * NRMSE_v', data=cre_cat_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check to see if the intercept is significantly different\n",
    "int_same_model=smf.ols(formula='NRMSE_i ~ NRMSE_v', data=cre_cat_df).fit()\n",
    "int_diff_model=smf.ols(formula='NRMSE_i ~ cre_catagory + NRMSE_v', data=cre_cat_df).fit()\n",
    "sm.stats.anova_lm(int_diff_model, int_same_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_same_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to see if slopes are significantly different\n",
    "sm.stats.anova_lm(int_diff_model, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot all the data\n",
    "matplotlib.rc('font', **font)\n",
    "cre_plots(excellent_df, 'cre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "import matplotlib.image as mpimg\n",
    "for p in excellent_df[['image_path_i', 'image_path_v']].iterrows():\n",
    "#    if type(p) is str:\n",
    "    print (p[1].image_path_i)\n",
    "    print (p[1].image_path_v)    \n",
    "#     display(Image(filename=p[1].image_path_i, width=400, height=400))\n",
    "#     display(Image(filename=p[1].image_path_v, width=400, height=400)) \n",
    "    f=plt.figure(figsize=(20,10))\n",
    "    f.add_subplot(121)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_i))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(122)\n",
    "    plt.imshow(mpimg.imread(p[1].image_path_v)) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
